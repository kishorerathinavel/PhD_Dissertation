@InProceedings{Akeley2004,
  author    = {Akeley, Kurt and Watt, Simon J. and Girshick, Ahna Reza and Banks, Martin S.},
  title     = {{A Stereo Display Prototype with Multiple Focal Distances}},
  booktitle = {ACM SIGGRAPH 2004 Papers},
  year      = {2004},
  series    = {SIGGRAPH '04},
  pages     = {804--813},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1015804},
  doi       = {10.1145/1186562.1015804},
  file      = {:Akeley2004 - A stereo display prototype with multiple focal distances. TOG.pdf:PDF},
  groups    = {All entries},
  keywords  = {graphics hardware, hardware systems, optics, user-interface hardware, virtual reality},
  location  = {Los Angeles, California},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1186562.1015804},
}

@article {Padmanaban2019Autofocals,
	author = {Padmanaban, Nitish and Konrad, Robert and Wetzstein, Gordon},
	title = {Autofocals: Evaluating gaze-contingent eyeglasses for presbyopes},
	year = {2019},
	journal = {Science Advances},
}


@article{Watt2005,
  title={Focus cues affect perceived depth},
  author={Watt, Simon J and Akeley, Kurt and Ernst, Marc O and Banks, Martin S},
  journal={Journal of vision},
  volume={5},
  number={10},
  pages={7--7},
  year={2005},
  publisher={The Association for Research in Vision and Ophthalmology},
}


@article{Campbell1957,
  title={The depth of field of the human eye},
  author={Campbell, Fergus W},
  journal={Optica Acta: International Journal of Optics},
  volume={4},
  number={4},
  pages={157--164},
  year={1957},
  publisher={Taylor \& Francis},
}


@inproceedings{Langlotz2018,
 author = {Langlotz, Tobias and Sutton, Jonathan and Zollmann, Stefanie and Itoh, Yuta and Regenbrecht, Holger},
 title = {ChromaGlasses: Computational Glasses for Compensating Colour Blindness},
 booktitle = {Proc. SIGCHI},
 year = {2018},
 pages = {390:1--390:12},
}


@ARTICLE{Langlotz:2016, 
author={T. {Langlotz} and M. {Cook} and H. {Regenbrecht}}, 
journal={IEEE TVCG}, 
title={Real-Time Radiometric Compensation for Optical See-Through Head-Mounted Displays}, 
year={2016}, 
volume={22}, 
number={11}, 
pages={2385-2394}, 
}


@inproceedings{Lanman2010,
 author = {Lanman, Douglas and Hirsch, Matthew and Kim, Yunhee and Raskar, Ramesh},
 title = {Content-adaptive Parallax Barriers: Optimizing Dual-layer 3D Displays Using Low-rank Light Field Factorization},
 booktitle = {ACM SIGGRAPH Asia},
 year = {2010},
 pages = {163:1--163:10},
} 


@article{Wetzstein2012,
 author = {Wetzstein, Gordon and Lanman, Douglas and Hirsch, Matthew and Raskar, Ramesh},
 title = {Tensor Displays: Compressive Light Field Synthesis Using Multilayer Displays with Directional Backlighting},
 journal = {ACM Trans. Graph. (SIGGRAPH)},
 volume = {31},
 number = {4},
 year = {2012},
 pages = {80:1--80:11},
} 


@article{Maimone2014,
 author = {Maimone, Andrew and Lanman, Douglas and Rathinavel, Kishore and Keller, Kurtis and Luebke, David and Fuchs, Henry},
 title = {Pinlight Displays: Wide Field of View Augmented Reality Eyeglasses Using Defocused Point Light Sources},
 journal = {ACM Trans. Graph. (SIGGRAPH)},
 volume = {33},
 number = {4},
 year = {2014},
 pages = {89:1--89:11},
} 


@article{Yamaguchi2016,
author = {Yuta Yamaguchi and Yasuhiro Takaki},
journal = {OSA Appl. Opt.},
number = {3},
pages = {A144--A149},
title = {See-through integral imaging display with background occlusion capability},
volume = {55},
year = {2016},
}


@article{Rolland2000,
author = {Rolland, Jannick P. and Fuchs, Henry},
title = {Optical Versus Video See-Through Head-Mounted Displays in Medical Visualization},
journal = {Presence: Teleoperators and Virtual Environments},
volume = {9},
number = {3},
pages = {287-309},
year = {2000},
doi = {10.1162/105474600566808},
URL = {  https://doi.org/10.1162/105474600566808  },
eprint = {  https://doi.org/10.1162/105474600566808  } ,
abstract = { We compare two technological approaches to augmented reality for 3-D medical visualization: optical and video see-through devices. We provide a context to discuss the technology by reviewing several medical applications of augmented-reality re search efforts driven by real needs in the medical field, both in the United States and in Europe. We then discuss the issues for each approach, optical versus video, from both a technology and human-factor point of view. Finally, we point to potentially promising future developments of such devices including eye tracking and multifocus planes capabilities, as well as hybrid optical/video technology. }
}


@article{Choi2015,
author = {Joseph S. Choi and John C. Howell},
journal = {OSA Opt. Express},
number = {24},
pages = {29465--29478},
title = {Paraxial ray optics cloaking},
volume = {22},
year = {2014},
}



@article{Wetzstein2010,
author = {Wetzstein, Gordon and Heidrich, Wolfgang and Luebke, David},
title = {Optical Image Processing Using Light Modulation Displays},
journal = {Computer Graphics Forum},
volume = {29},
year = {2010},
number = {6},
pages = {1934-1944},
}


@inproceedings{Gao2013optical,
  title={Optical see-through head-mounted display with occlusion capability},
  author={Gao, Chunyu and Lin, Yuxiang and Hua, Hong},
  booktitle={Proc. SPIE 8735},
  year={2013},
}


@article{Wilson2017,
author = {Austin Wilson and Hong Hua},
journal = {OSA Opt. Express},
number = {24},
pages = {30539--30549},
title = {Design and prototype of an augmented reality display with per-pixel mutual occlusion capability},
volume = {25},
year = {2017},
}


@article{Kiyokawa2001,
  title={An optical see-through display for mutual occlusion with a real-time stereovision system},
  author={Kiyokawa, Kiyoshi and Kurata, Yoshinori and Ohno, Hiroyuki},
  journal={Computers \& Graphics},
  volume={25},
  number={5},
  pages={765--779},
  year={2001},
}


@inproceedings{Kiyokawa2000,
  title={An optical see-through display for mutual occlusion of real and virtual environments.},
  author={Kiyokawa, Kiyoshi and Kurata, Yoshinori and Ohno, Hiroyuki},
  booktitle={Proc. ISAR},
  pages={60--67},
  year={2000}
}


@inproceedings{avveduto2017real,
  title={Real-world occlusion in optical see-through AR displays},
  author={Avveduto, Giovanni and Tecchia, Franco and Fuchs, Henry},
  booktitle={Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology},
  pages={29},
  year={2017},
  organization={ACM}
}


@inproceedings{maimone2013general,
  title={General-purpose telepresence with head-worn optical see-through displays and projector-based lighting},
  author={Maimone, Andrew and Yang, Xubo and Dierk, Nate and State, Andrei and Dou, Mingsong and Fuchs, Henry},
  booktitle={2013 IEEE Virtual Reality (VR)},
  pages={23--26},
  year={2013},
  organization={IEEE}
}


@inproceedings{bimber2003consistent,
  title={Consistent illumination within optical see-through augmented environments},
  author={Bimber, Oliver and Grundh\"ofer, Anselm and Wetzstein, Gordon and Kn\"odel, Sebastian},
  booktitle={Proc. IEEE ISMAR},
  pages={198--207},
  year={2003},
}


@inproceedings{Bimber:2002,
 author = {Bimber, Oliver and Fr\"{o}hlich, Bernd},
 title = {Occlusion Shadows: Using Projected Light to Generate Realistic Occlusion Effects for View-Dependent Optical See-Through Displays},
 booktitle = {Proc. IEEE ISMAR},
 year = {2002},
} 


@article{kooi2004visual,
  title={Visual comfort of binocular and 3D displays},
  author={Kooi, Frank L and Toet, Alexander},
  journal={Displays},
  volume={25},
  number={2-3},
  pages={99--108},
  year={2004},
  publisher={Elsevier}
}


@article{lambooij2009visual,
  title={Visual discomfort and visual fatigue of stereoscopic displays: A review},
  author={Lambooij, Marc and Fortuin, Marten and Heynderickx, Ingrid and IJsselsteijn, Wijnand},
  journal={Journal of Imaging Science and Technology},
  volume={53},
  number={3},
  pages={30201--1},
  year={2009},
  publisher={Society for Imaging Science and Technology}
}

@article {Bimber:2008,
journal = {Computer Graphics Forum},
title = {{The Visual Computing of Projector-Camera Systems}},
author = {Bimber, Oliver and Iwai, Daisuke and Wetzstein, Gordon and Grundhoefer, Anselm},
year = {2008},
}


@ARTICLE{Hamasaki2019, 
author={T. {Hamasaki} and Y. {Itoh}}, 
journal={IEEE TVCG}, 
title={Varifocal Occlusion for Optical See-Through Head-Mounted Displays using a Slide Occlusion Mask}, 
year={2019}, 
volume={25}, 
number={5}, 
pages={1961-1969}, 
}


@article{Howlett2017,
  title={Perspective correct occlusion-capable augmented reality displays using cloaking optics constraints},
  author={Howlett, Isela D and Smithwick, Quinn},
  journal={Journal of the Society for Information Display},
  volume={25},
  number={3},
  pages={185--193},
  year={2017},
}


@article{Shiwa1996proposal,
  title={Proposal for a 3-D display with accommodative compensation: 3DDAC},
  author={Shiwa, Shinichi and Omura, Katsuyuki and Kishino, Fumio},
  journal={Journal of the Society for Information Display},
  volume={4},
  number={4},
  pages={255--261},
  year={1996},
  publisher={Wiley Online Library}
}


@article{Johnson:16,
author = {Paul V. Johnson and Jared AQ. Parnell and Joohwan Kim and Christopher D. Saunter and Gordon D. Love and Martin S. Banks},
journal = {OSA Opt. Express},
number = {11},
pages = {11808--11827},
title = {Dynamic lens and monovision 3D displays to improve viewer comfort},
volume = {24},
year = {2016},
}


@inproceedings{Laffont:2018,
 author = {Laffont, Pierre-Yves and Hasnain, Ali and Guillemet, Pierre-Yves and Wirajaya, Samuel and Khoo, Joe and Teng, Deng and Bazin, Jean-Charles},
 title = {Verifocal: A Platform for Vision Correction and Accommodation in Head-mounted Displays},
 booktitle = {ACM SIGGRAPH 2018 Emerging Technologies},
 year = {2018},
 pages = {21:1--21:2},
 } 

@INPROCEEDINGS{Maimone2013,
author = {A. Maimone and H. Fuchs},
booktitle = {Proc. IEEE ISMAR},
title = {Computational augmented reality eyeglasses},
year = {2013},
pages = {29-38},
}


@ARTICLE{Itoh2017,
author={Y. Itoh and T. Hamasaki and M. Sugimoto},
journal={IEEE TVCG},
title={Occlusion Leak Compensation for Optical See-Through Displays Using a Single-Layer Transmissive Spatial Light Modulator},
year={2017},
volume={23},
number={11},
pages={2463-2473},
}


@ARTICLE{Itoh2019, 
author={Y. {Itoh} and T. {Langlotz} and D. {Iwai} and K. {Kiyokawa} and T. {Amano}}, 
journal={IEEE TVCG}, 
title={Light Attenuation Display: Subtractive See-Through Near-Eye Display via Spatial Color Filtering}, 
year={2019}, 
volume={25}, 
number={5}, 
pages={1951-1960}, 
}


@inproceedings{Cakmakci2005,
  title={Design of a compact optical see-through head-worn display with mutual occlusion capability},
  author={Cakmakci, Ozan and Ha, Yonggang and Rolland, Jannick},
  booktitle={Proc. SPIE 5875},
  year={2005},
}


@inproceedings{Cakmakci2004,
 author = {Cakmakci, Ozan and Ha, Yonggang and Rolland, Jannick P.},
 title = {A Compact Optical See-Through Head-Worn Display with Occlusion Support},
 booktitle = {Proc. IEEE ISMAR},
 year = {2004},
 pages = {16--25},
} 


@INPROCEEDINGS{Gao2012,
author={C. Gao and Y. Lin and H. Hua},
booktitle={Proc. IEEE ISMAR},
title={Occlusion capable optical see-through head-mounted display using freeform optics},
year={2012},
volume={},
number={},
pages={281-282},
}


@inproceedings{Kiyokawa2003,
 author = {Kiyokawa, Kiyoshi and Billinghurst, Mark and Campbell, Bruce and Woods, Eric},
 title = {An Occlusion-Capable Optical See-through Head Mount Display for Supporting Co-located Collaboration},
 booktitle = {Proc. IEEE ISMAR},
 year = {2003},
} 

@INPROCEEDINGS{Mori2018,
author={S. Mori and S. Ikeda and A. Plopski and C. Sandor},
booktitle={Proc. IEEE VR},
title={BrightView: Increasing Perceived Brightness of Optical See-Through Head-Mounted Displays Through Unnoticeable Incident Light Reduction},
year={2018},
volume={},
number={},
pages={251-258},
}

@incollection{Cutting:1995,
  author      = "James Cutting and Peter Vishton",
  title       = "Perceiving layout and knowing distances: The interaction, relative potency, and contextual use of different information about depth",
  editor      = "William Epstein and Sheena Rogers",
  booktitle   = "Perception of Space and Motion",
  publisher   = "Academic Press",
  year        = 1995,
  pages       = "69-117",
  chapter     = 3,
}


@book{Howard:2002,
  AUTHOR =       {Ian P. Howard and Brian J. Rogers},
  TITLE =        {Seeing in Depth},
  PUBLISHER =    {Oxford University Press},
  YEAR =         {2002},
}

@book{Palmer:1999,
  AUTHOR =       {Stephen E. Palmer},
  TITLE =        {Vision Science - Photons to Phenomenology},
  PUBLISHER =    {MIT Press},
  YEAR =         {1999},
}

@INPROCEEDINGS{Liu2008Optical, 
author={Sheng Liu and Dewen Cheng and Hong Hua}, 
booktitle={Proc. IEEE ISMAR}, 
title={An optical see-through head mounted display with addressable focal planes}, 
year={2008}, 
pages={33-42}, 
}

@ARTICLE{Rathinavel2018, 
author={K. {Rathinavel} and H. {Wang} and A. {Blate} and H. {Fuchs}}, 
journal={IEEE TVCG}, 
title={An Extended Depth-at-Field Volumetric Near-Eye Augmented Reality Display}, 
year={2018}, 
volume={24}, 
number={11}, 
pages={2857-2866}, 
}

@article{chakravarthula2018focusar,
  title={Focusar: Auto-focus augmented reality eyeglasses for both real world and virtual imagery},
  author={Chakravarthula, Praneeth and Dunn, David and Ak{\c{s}}it, Kaan and Fuchs, Henry},
  journal={IEEE transactions on visualization and computer graphics},
  volume={24},
  number={11},
  pages={2906--2916},
  year={2018},
  publisher={IEEE}
}

@article{sielhorst2008advanced,
  title={Advanced medical displays: A literature review of augmented reality},
  author={Sielhorst, Tobias and Feuerstein, Marco and Navab, Nassir},
  journal={Journal of Display Technology},
  volume={4},
  number={4},
  pages={451--467},
  year={2008},
  publisher={IEEE}
}

@incollection{cutting1995perceiving,
  title={Perceiving layout and knowing distances: The integration, relative potency, and contextual use of different information about depth},
  author={Cutting, James E and Vishton, Peter M},
  booktitle={Perception of space and motion},
  pages={69--117},
  year={1995},
  publisher={Elsevier}
}


@inproceedings{mills1984high,
  title={High-speed interaction on a vibrating-mirror 3D display},
  author={Mills, Peter H and Fuchs, Henry and Pizer, Stephen M},
  booktitle={Processing and Display of Three-Dimensional Data II},
  volume={507},
  pages={93--102},
  year={1984},
  organization={International Society for Optics and Photonics}
}

@article{wang2018digitally,
  title={Digitally switchable multi-focal lens using freeform optics},
  author={Wang, Xuan and Qin, Yi and Hua, Hong and Lee, Yun-Han and Wu, Shin-Tson},
  journal={Optics express},
  volume={26},
  number={8},
  pages={11007--11017},
  year={2018},
  publisher={Optical Society of America}
}

@inproceedings{Lee2018Shape,
  title={Shape scanning displays: tomographic decomposition of 3D scenes},
  author={Lee, Seungjae and Jo, Youngjin and Yoo, Dongheon and Cho, Jaebum and Lee, Dukho and Lee, Byoungho},
  booktitle={Digital Optics for Immersive Displays},
  volume={10676},
  pages={1067617},
  year={2018},
  organization={International Society for Optics and Photonics}
}

@article{Lee2018Tomoreal,
  title={Tomoreal: Tomographic displays},
  author={Lee, Seungjae and Jo, Youngjin and Yoo, Dongheon and Cho, Jaebum and Lee, Dukho and Lee, Byoungho},
  journal={arXiv preprint arXiv:1804.04619},
  year={2018}
}


@article{Konrad2017Accommodation,
 author = {Konrad, Robert and Padmanaban, Nitish and Molner, Keenan and Cooper, Emily A. and Wetzstein, Gordon},
 title = {Accommodation-invariant Computational Near-eye Displays},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2017},
 volume = {36},
 number = {4},
 month = jul,
 year = {2017},
 issn = {0730-0301},
 pages = {88:1--88:12},
 articleno = {88},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3072959.3073594},
 doi = {10.1145/3072959.3073594},
 acmid = {3073594},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational displays, vergence-accommodation conflict},
} 


@article{liu2009time,
  title={Time-multiplexed dual-focal plane head-mounted display with a liquid lens},
  author={Liu, Sheng and Hua, Hong},
  journal={Optics letters},
  volume={34},
  number={11},
  pages={1642--1644},
  year={2009},
  publisher={Optical Society of America}
}

@proceeding{Shevlin2005Fixed,
author = {Fergal  Shevlin},
title = {A fixed-viewpoint volumetric stereoscopic 3D display using adaptive optics},
journal = {Proc.SPIE},
volume = {5664},
number = {},
pages = {5664 - 5664 - 6},
year = {2005},
doi = {10.1117/12.585913},
URL = {https://doi.org/10.1117/12.585913},
eprint = {}
}

@proceeding{Watt2012Real,
author = { Simon J. Watt,Kevin J. MacKenzie,Louise  Ryan},
title = {Real-world stereoscopic performance in multiple-focal-plane displays: How far apart should the image planes be?},
journal = {Proc.SPIE},
volume = {8288},
number = {},
pages = {8288 - 8288 - 11},
year = {2012},
doi = {10.1117/12.908883},
URL = {https://doi.org/10.1117/12.908883},
eprint = {}
}


@article{Schowengerdt2006True,
  title={True 3-D scanned voxel displays using single or multiple light sources},
  author={Schowengerdt, Brian T and Seibel, Eric J},
  journal={Journal of the Society for Information Display},
  volume={14},
  number={2},
  pages={135--143},
  year={2006},
  publisher={Wiley Online Library}
}

@article{kim2015hovertable,
  title={HoVerTable: Combining Dual-sided Vertical Mid-air Images with a Horizontal Tabletop Display},
  author={Kim, Hanyuool and Yamamoto, Hiroki and Koizumi, Naoya and Maekawa, Satoshi and Naemura, Takeshi},
  journal={Information and Media Technologies},
  volume={10},
  number={4},
  pages={509--520},
  year={2015},
  publisher={Information and Media Technologies Editorial Board}
}

@inproceedings{Akeley2004stereo,
 author = {Akeley, Kurt and Watt, Simon J. and Girshick, Ahna Reza and Banks, Martin S.},
 title = {{A Stereo Display Prototype with Multiple Focal Distances}},
 booktitle = {ACM SIGGRAPH 2004 Papers},
 series = {SIGGRAPH '04},
 year = {2004},
 location = {Los Angeles, California},
 pages = {804--813},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1186562.1015804},
 doi = {10.1145/1186562.1015804},
 acmid = {1015804},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {graphics hardware, hardware systems, optics, user-interface hardware, virtual reality},
}

@article{Aksit2017Near,
 author = {Ak\c{s}it, Kaan and Lopes, Ward and Kim, Jonghyun and Shirley, Peter and Luebke, David},
 title = {{Near-eye Varifocal Augmented Reality Display Using See-through Screens}},
 journal = {ACM Trans. Graph.},
 issue_date = {November 2017},
 volume = {36},
 number = {6},
 month = nov,
 year = {2017},
 issn = {0730-0301},
 pages = {189:1--189:13},
 articleno = {189},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3130800.3130892},
 doi = {10.1145/3130800.3130892},
 acmid = {3130892},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality displays, computational displays, holographic optical elements, holography, near eye displays, see-through displays, varifocal displays},
}

@ARTICLE{Blundell2002, 
author={B. G. Blundell and A. J. Schwarz}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={The classification of volumetric display systems: characteristics and predictability of the image space}, 
year={2002}, 
volume={8}, 
number={1}, 
pages={66-75}, 
keywords={computer graphic equipment;three-dimensional displays;display unit subsystems;image space characteristics;image space predictability;volumetric display system classification;Computer displays;Computer graphics;Data visualization;Diversity methods;Electromagnetic wave absorption;Focusing;Prototypes;Scattering;Terminology;Three dimensional displays}, 
doi={10.1109/2945.981852}, 
ISSN={1077-2626}, 
month={Jan},}

@article{Cossairt2007Geometric,
author = {Oliver S. Cossairt and Joshua Napoli and Samuel L. Hill and Rick K. Dorval and Gregg E. Favalora},
journal = {Appl. Opt.},
keywords = {Geometric optical design; Computer holography; Holographic display; Multiplex holography; Three-dimensional image processing; Optical engineering},
number = {8},
pages = {1244--1250},
publisher = {OSA},
title = {Occlusion-capable multiview volumetric three-dimensional display},
volume = {46},
month = {Mar},
year = {2007},
url = {http://ao.osa.org/abstract.cfm?URI=ao-46-8-1244},
doi = {10.1364/AO.46.001244},
abstract = {Volumetric 3D displays are frequently purported to lack the ability to reconstruct scenes with viewer-position-dependent effects such as occlusion. To counter these claims, a swept-screen 198-view horizontal-parallax-only 3D display is reported here that is capable of viewer-position-dependent effects. A digital projector illuminates a rotating vertical diffuser with a series of multiperspective 768{\texttimes}768 pixel renderings of a 3D scene. Evidence of near-far object occlusion is reported. The aggregate virtual screen surface for a stationary observer is described, as are guidelines to construct a full-parallax system and the theoretical ability of the present system to project imagery outside of the volume swept by the screen.},
}

@article{Dewald2016Avegant,
author = {D. Scott Dewald and Allan T. Evans and Neil Welch and Andrew Gross and Geoff Hill},
title = {{The Avegant Glyph: Optical Design Considerations and Approach to Near‐eye Display}},
journal = {SID Symposium Digest of Technical Papers},
volume = {47},
number = {1},
year={2016},
pages = {69-71},
keywords = {Virtual reality, near‐eye display, DLP, Avegant Glyph},
doi = {10.1002/sdtp.10609},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sdtp.10609},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sdtp.10609},
abstract = {The Avegant Glyphtm is a new near‐eye product designed for mobile media consumption. It combines audio, a 3D capable display, head tracking, and other features into a novel product designed to mimic the movie theater experience. This paper will describe the evolution of the optical microdisplay system from early models to the final product, including novel illumination and projection optics that allow two complete projection engines to fit within the headband of the Glyph.}
}

@ARTICLE{Dunn2017Wide, 
author={D. Dunn and C. Tippets and K. Torell and P. Kellnhofer and K. Akşit and P. Didyk and K. Myszkowski and D. Luebke and H. Fuchs}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={{Wide Field Of View Varifocal Near-Eye Display Using See-Through Deformable Membrane Mirrors}}, 
year={2017}, 
volume={23}, 
number={4}, 
pages={1322-1331}, 
keywords={augmented reality;gaze tracking;image processing;mirrors;AR;FOV;NED;augmented reality;field of view;gaze tracking;near-eye display;varifocal deformable membrane mirror;virtual image;Holographic optical components;Holography;Image resolution;Mirrors;Optical imaging;Prototypes;Augmented reality;displays;focus accommodation;perception;user study}, 
doi={10.1109/TVCG.2017.2657058}, 
ISSN={1077-2626}, 
month={April},}

@inproceedings{Favalora2002100,
  title={100-million-voxel volumetric display},
  author={Favalora, Gregg E and Napoli, Joshua and Hall, Deirdre M and Dorval, Rick K and Giovinco, Michael and Richmond, Michael J and Chun, Won S},
  booktitle={Cockpit Displays IX: Displays for Defense Applications},
  volume={4712},
  pages={300--313},
  year={2002},
  organization={International Society for Optics and Photonics},
doi = {10.1117/12.480930},
URL = {https://doi.org/10.1117/12.480930}
}


@article{Hoffman2008Vergence,
author = {Hoffman, David M. and Girshick, Ahna R. and Akeley, Kurt and Banks, Martin S.},
title = {Vergence – accommodation conflicts hinder visual performance and cause visual fatigue},
journal = {Journal of Vision},
volume = {8},
number = {3},
pages = {33},
year = {2008},
doi = {10.1167/8.3.33},
URL = { + http://dx.doi.org/10.1167/8.3.33},
eprint = {/data/journals/jov/932853/jov-8-3-33.pdf}
}

@ARTICLE{Holliman2011Three, 
author={N. S. Holliman and N. A. Dodgson and G. E. Favalora and L. Pockett}, 
journal={IEEE Transactions on Broadcasting}, 
title={Three-Dimensional Displays: A Review and Applications Analysis}, 
year={2011}, 
volume={57}, 
number={2}, 
pages={362-371}, 
keywords={image resolution;stereo image processing;three-dimensional displays;3D display;Benton taxonomy;image delivery;three-dimensional display;Glass;Head;Image color analysis;Optical switches;Optical waveguides;Three dimensional displays;Human factors;image resolution;stereo vision;three dimensional displays}, 
doi={10.1109/TBC.2011.2130930}, 
ISSN={0018-9316}, 
month={June},}

@Article{Hsu2017HoloTube,
author="Hsu, Che-Hao
and Wu, Yi-Leh
and Cheng, Weng-Huang
and Chen, Yu-Jen
and Hua, Kai-Lung",
title="HoloTube: a low-cost portable 360-degree interactive autostereoscopic display",
journal="Multimedia Tools and Applications",
year="2017",
month="Apr",
day="01",
volume="76",
number="7",
pages="9099--9132",
abstract="This paper proposes a novel, low cost, and portable 360-degree cylindrical interactive autostereoscopic 3D display system. The proposed system consists of three parts: the optical architecture (for back-projecting image correctly on the cylindrical screen), the projection image transformation workflow (for image rectifying and generating multi-view images), and the 360-degree motion detection module (for identifying viewers' locations and providing the corresponding views). Based on the proposed design, only one commercial micro projector is employed for the proposed cylindrical screen. The proposed display offers great depth perception (stereoacuity) with a special designed thick barrier sheet attached to the screen. The viewers are not required to wear special glasses and within appropriate range (< 5m) the viewers can view the screen at any distance and angle. The user study verified that the proposed display offers satisfactory depth perception (binocular parallax, shading distribution, and linear perspective) for various viewing distances and angles without noticeable discomfort. The production cost of the current prototype is about USD{\$} 300. With mass production, the unit cost is expected to decline to within USD{\$}60. The proposed display system has the advantages of ease of use, low production cost, high portability and mobility. The proposed system is suitable for application such as museum virtual exhibition, remote meeting, multi-user online game, etc. We believe that the proposed system is very promising for the market of low-cost portable 360-degree interactive autosereoscopic displays.",
issn="1573-7721",
doi="10.1007/s11042-016-3502-3",
url="https://doi.org/10.1007/s11042-016-3502-3"
}



@ARTICLE{Hua2017Enabling, 
author={H. Hua}, 
journal={Proceedings of the IEEE}, 
title={{Enabling Focus Cues in Head-Mounted Displays}}, 
year={2017}, 
volume={105}, 
number={5}, 
pages={805-824}, 
keywords={augmented reality;helmet mounted displays;rendering (computer graphics);AR application;HMD;VR application;augmented reality application;digital world;focus cue;head-mounted displays;human factor;natural eye accommodation response stimulation;optical pathway;physical world;technological perspective;vergence-accommodation conflict problem;virtual reality application;visual discomfort minimization;Adaptive optics;Augmented reality;Convergence;Optical imaging;Retina;Stereo image processing;Three-dimensional displays;Virtual reality;Visualization;Accommodation and convergence;augmented reality;focus cues;head-mounted displays (HMDs);near-to-eye displays;virtual reality (VR)}, 
doi={10.1109/JPROC.2017.2648796}, 
ISSN={0018-9219}, 
month={May},}

@article{Hua2014Three,
author = {Hong Hua and Bahram Javidi},
journal = {Opt. Express},
keywords = {Three-dimensional image acquisition; Displays; Heads-up displays; Optical design of instruments; Visually coupled optical systems},
number = {11},
pages = {13484--13491},
publisher = {OSA},
title = {{A 3D integral imaging optical see-through head-mounted display}},
volume = {22},
month = {Jun},
year = {2014},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-22-11-13484},
doi = {10.1364/OE.22.013484},
abstract = {An optical see-through head-mounted display (OST-HMD), which enables optical superposition of digital information onto the direct view of the physical world and maintains see-through vision to the real world, is a vital component in an augmented reality (AR) system. A key limitation of the state-of-the-art OST-HMD technology is the well-known accommodation-convergence mismatch problem caused by the fact that the image source in most of the existing AR displays is a 2D flat surface located at a fixed distance from the eye. In this paper, we present an innovative approach to OST-HMD designs by combining the recent advancement of freeform optical technology and microscopic integral imaging (micro-InI) method. A micro-InI unit creates a 3D image source for HMD viewing optics, instead of a typical 2D display surface, by reconstructing a miniature 3D scene from a large number of perspective images of the scene. By taking advantage of the emerging freeform optical technology, our approach will result in compact, lightweight, goggle-style AR display that is potentially less vulnerable to the accommodation-convergence discrepancy problem and visual fatigue. A proof-of-concept prototype system is demonstrated, which offers a goggle-like compact form factor, non-obstructive see-through field of view, and true 3D virtual display.},
}

@article{Huang2015Light,
 author = {Huang, Fu-Chung and Chen, Kevin and Wetzstein, Gordon},
 title = {{The Light Field Stereoscope: Immersive Computer Graphics via Factored Near-eye Light Field Displays with Focus Cues}},
 journal = {ACM Trans. Graph.},
 issue_date = {August 2015},
 volume = {34},
 number = {4},
 month = jul,
 year = {2015},
 issn = {0730-0301},
 pages = {60:1--60:12},
 articleno = {60},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2766922},
 doi = {10.1145/2766922},
 acmid = {2766922},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational displays, focus cues, light fields},
}

@ARTICLE{Hu2014design, 
author={X. Hu and H. Hua}, 
journal={Journal of Display Technology}, 
title={{Design and Assessment of a Depth-Fused Multi-Focal-Plane Display Prototype}}, 
year={2014}, 
volume={10}, 
number={4}, 
pages={308-316}, 
keywords={focal planes;image fusion;optical design techniques;rendering (computer graphics);stereo image processing;three-dimensional displays;depth fused multifocal plane display prototype;depth fused six focal plane display prototype assessment;depth fused six focal plane display prototype design;diopters;discrete focal plane placement;fixed viewpoint volumetric display;focus cues rendering;image quality;negative effects;optical system design;stereoscopic display;Lenses;Mirrors;Optical imaging;Prototypes;Retina;Stereo image processing;Three-dimensional displays;Depth-fused display;eye accommodation;multi-focal-plane display;stereoscopic 3D display}, 
doi={10.1109/JDT.2014.2300752}, 
ISSN={1551-319X}, 
month={April},}

@article{Hu2014High,
author = {Xinda Hu and Hong Hua},
journal = {Opt. Express},
keywords = {Displays; Heads-up displays; Optical design of instruments; Aspherics; Lens system design; Visually coupled optical systems},
number = {11},
pages = {13896--13903},
publisher = {OSA},
title = {High-resolution optical see-through multi-focal-plane head-mounted display using freeform optics},
volume = {22},
month = {Jun},
year = {2014},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-22-11-13896},
doi = {10.1364/OE.22.013896},
abstract = {Conventional stereoscopic displays force an unnatural decoupling of the accommodation and convergence cues, which may contribute to various visual artifacts and have adverse effects on depth perception accuracy. In this paper, we present the design and implementation of a high-resolution optical see-through multi-focal-plane head-mounted display enabled by state-of-the-art freeform optics. The prototype system is capable of rendering nearly-correct focus cues for a large volume of 3D space, extending into a depth range from 0 to 3 diopters. The freeform optics, consisting of a freeform prism eyepiece and a freeform lens, demonstrates an angular resolution of 1.8 arcminutes across a 40-degree diagonal field of view in the virtual display path while providing a 0.5 arcminutes angular resolution to the see-through view.},
}

@article{Hu2015Design,
author = {Xinda Hu and Hong Hua},
journal = {Appl. Opt.},
keywords = {Heads-up displays; Aspherics; Lens system design; Fabrication, tolerancing},
number = {33},
pages = {9990--9999},
publisher = {OSA},
title = {Design and tolerance of a free-form optical system for an optical see-through multi-focal-plane display},
volume = {54},
month = {Nov},
year = {2015},
url = {http://ao.osa.org/abstract.cfm?URI=ao-54-33-9990},
doi = {10.1364/AO.54.009990},
abstract = {By elegantly combining recent advancements of free-form optical technology and multi-focal-plane (MFP) display technology, we developed a high-performance true 3D augmented reality (AR) display that is capable of rendering a large volume of 3D scenes with accurate focus cues; this display overcomes the accommodation-convergence discrepancy problem in conventional AR display. In this paper, we concentrate on various aspects of engineering challenges in the design and integration of a free-form optical see-through eyepiece with MFP technology for our AR display prototype. We present the design and optimization strategy in coupling free-form optics with a rotational-symmetric lens system to achieve high image quality. A comprehensive tolerance analysis of this complicated optical system is also presented, including an effective tolerance method for random surface figure errors on aspheric and free-form surfaces. Finally, the image quality of the virtual display is evaluated, which shows the as-built performance matches very well with the optical design results and tolerance analysis.},
}

@article{Jang2017Retinal,
 author = {Jang, Changwon and Bang, Kiseung and Moon, Seokil and Kim, Jonghyun and Lee, Seungjae and Lee, Byoungho},
 title = {{Retinal 3D: Augmented Reality Near-eye Display via Pupil-tracked Light Field Projection on Retina}},
 journal = {ACM Trans. Graph.},
 issue_date = {November 2017},
 volume = {36},
 number = {6},
 month = nov,
 year = {2017},
 issn = {0730-0301},
 pages = {190:1--190:13},
 articleno = {190},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3130800.3130889},
 doi = {10.1145/3130800.3130889},
 acmid = {3130889},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational displays, eye tracking, holographic optical element, near-eye display, vergence-accommodation conflict},
}

@article{Johnson2016Dynamic,
author = {Paul V. Johnson and Jared AQ. Parnell and Joohwan Kim and Christopher D. Saunter and Gordon D. Love and Martin S. Banks},
journal = {Opt. Express},
keywords = {Active or adaptive optics; Displays; Lenses; Vision - binocular and stereopsis},
number = {11},
pages = {11808--11827},
publisher = {OSA},
title = {Dynamic lens and monovision 3D displays to improve viewer comfort},
volume = {24},
month = {May},
year = {2016},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-24-11-11808},
doi = {10.1364/OE.24.011808},
abstract = {Stereoscopic 3D (S3D) displays provide an additional sense of depth compared to non-stereoscopic displays by sending slightly different images to the two eyes. But conventional S3D displays do not reproduce all natural depth cues. In particular, focus cues are incorrect causing mismatches between accommodation and vergence: The eyes must accommodate to the display screen to create sharp retinal images even when binocular disparity drives the eyes to converge to other distances. This mismatch causes visual discomfort and reduces visual performance. We propose and assess two new techniques that are designed to reduce the vergence-accommodation conflict and thereby decrease discomfort and increase visual performance. These techniques are much simpler to implement than previous conflict-reducing techniques. The first proposed technique uses variable-focus lenses between the display and the viewer\&\#x2019;s eyes. The power of the lenses is yoked to the expected vergence distance thereby reducing the mismatch between vergence and accommodation. The second proposed technique uses a fixed lens in front of one eye and relies on the binocularly fused percept being determined by one eye and then the other, depending on simulated distance. We conducted performance tests and discomfort assessments with both techniques and compared the results to those of a conventional S3D display. The first proposed technique, but not the second, yielded clear improvements in performance and reductions in discomfort. This dynamic-lens technique therefore offers an easily implemented technique for reducing the vergence-accommodation conflict and thereby improving viewer experience.},
}

@inproceedings{Jones2007Rendering,
 author = {Jones, Andrew and McDowall, Ian and Yamada, Hideshi and Bolas, Mark and Debevec, Paul},
 title = {{Rendering for an Interactive $360^\circ$ Light Field Display}},
 booktitle = {ACM SIGGRAPH 2007 Papers},
 series = {SIGGRAPH '07},
 year = {2007},
 location = {San Diego, California},
 articleno = {40},
 url = {http://doi.acm.org/10.1145/1275808.1276427},
 doi = {10.1145/1275808.1276427},
 acmid = {1276427},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {autostereocopic displays, graphics hardware, image-based rendering, light field, real-time rendering},
}

@inproceedings{Kaufman19873d,
 author = {Kaufman, Arie and Shimony, Eyal},
 title = {{3D Scan-conversion Algorithms for Voxel-based Graphics}},
 booktitle = {Proceedings of the 1986 Workshop on Interactive 3D Graphics},
 series = {I3D '86},
 year = {1987},
 isbn = {0-89791-228-4},
 location = {Chapel Hill, North Carolina, USA},
 pages = {45--75},
 numpages = {31},
 url = {http://doi.acm.org/10.1145/319120.319126},
 doi = {10.1145/319120.319126},
 acmid = {319126},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{Kaufman1987efficient,
 author = {Kaufman, Arie},
 title = {{Efficient Algorithms for 3D Scan-conversion of Parametric Curves, Surfaces, and Volumes}},
 booktitle = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques},
 series = {SIGGRAPH '87},
 year = {1987},
 isbn = {0-89791-227-6},
 pages = {171--179},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/37401.37423},
 doi = {10.1145/37401.37423},
 acmid = {37423},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@ARTICLE{Kaufman1988memory, 
author={A. Kaufman and R. Bakalash}, 
journal={IEEE Computer Graphics and Applications}, 
title={{Memory and processing architecture for 3D voxel-based imagery}}, 
year={1988}, 
volume={8}, 
number={6}, 
pages={10-23}, 
keywords={computer architecture;computer graphic equipment;computerised picture processing;memory architecture;multiprocessing systems;real-time systems;3-D cubic frame buffer;3-D volume visualization;Cube architecture;computer architecture;computer graphics;frame buffer;memory architecture;multiple-write bus;picture processing;real-time;skewed memory organization;voxel systems;voxel-based architecture;Buffer storage;Computed tomography;Graphics;Hardware;Memory architecture;Prototypes;Real time systems;Rendering (computer graphics);Skull;Solid modeling}, 
doi={10.1109/38.20314}, 
ISSN={0272-1716}, 
month={Nov},}

@INPROCEEDINGS{Kim2007see, 
author={S. K. Kim and D. W. Kim and M. C. Park and J. Y. Son}, 
booktitle={2007 3DTV Conference}, 
title={{See through HMD type MF 3D display for AR}}, 
year={2007}, 
volume={}, 
number={}, 
pages={1-4}, 
keywords={augmented reality;helmet mounted displays;LED;MF 3D display;computer-generated virtual information;eye fatigue;image display system;monocular depth;parallax images;problem solving;virtual objects;Application software;Computer displays;Convergence;Eyes;Fatigue;Humans;Image generation;Light emitting diodes;Testing;Three dimensional displays;3-dimensional display;AR;MR;VR;accommodation;convergence;eye fatigue;multi-focus;see through HMD}, 
doi={10.1109/3DTV.2007.4379407}, 
ISSN={2161-2021}, 
month={May},}

@inproceedings{Kimura2006Laser,
 author = {Kimura, Hidei and Uchiyama, Taro and Yoshikawa, Hiroyuki},
 title = {Laser Produced 3D Display in the Air},
 booktitle = {ACM SIGGRAPH 2006 Emerging Technologies},
 series = {SIGGRAPH '06},
 year = {2006},
 isbn = {1-59593-364-6},
 location = {Boston, Massachusetts},
 articleno = {20},
 url = {http://doi.acm.org/10.1145/1179133.1179154},
 doi = {10.1145/1179133.1179154},
 acmid = {1179154},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Kimura2011True,
 author = {Kimura, Hidei and Asano, Akira and Fujishiro, Issei and Nakatani, Ayaka and Watanabe, Hayato},
 title = {True 3D Display},
 booktitle = {ACM SIGGRAPH 2011 Emerging Technologies},
 series = {SIGGRAPH '11},
 year = {2011},
 isbn = {978-1-4503-0969-1},
 location = {Vancouver, British Columbia, Canada},
 pages = {20:1--20:1},
 articleno = {20},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/2048259.2048279},
 doi = {10.1145/2048259.2048279},
 acmid = {2048279},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Konrad2016Novel,
 author = {Konrad, Robert and Cooper, Emily A. and Wetzstein, Gordon},
 title = {Novel Optical Configurations for Virtual Reality: Evaluating User Preference and Performance with Focus-tunable and Monovision Near-eye Displays},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {San Jose, California, USA},
 pages = {1211--1220},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2858036.2858140},
 doi = {10.1145/2858036.2858140},
 acmid = {2858140},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {focus cues, user comfort, user performance, virtual reality},
} 

@article{Konrad2017accommodation,
 author = {Konrad, Robert and Padmanaban, Nitish and Molner, Keenan and Cooper, Emily A. and Wetzstein, Gordon},
 title = {{Accommodation-invariant Computational Near-eye Displays}},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2017},
 volume = {36},
 number = {4},
 month = jul,
 year = {2017},
 issn = {0730-0301},
 pages = {88:1--88:12},
 articleno = {88},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3072959.3073594},
 doi = {10.1145/3072959.3073594},
 acmid = {3073594},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational displays, vergence-accommodation conflict},
} 

@article{Koutaki2016Binary,
 author = {Koutaki, Gou},
 title = {{Binary Continuous Image Decomposition for Multi-view Display}},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2016},
 volume = {35},
 number = {4},
 month = jul,
 year = {2016},
 issn = {0730-0301},
 pages = {69:1--69:12},
 articleno = {69},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2897824.2925949},
 doi = {10.1145/2897824.2925949},
 acmid = {2925949},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D display, DLP, active shutter, stereoscopic},
}


@ARTICLE{Kramida2016Resolving, 
author={G. Kramida}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Resolving the Vergence-Accommodation Conflict in Head-Mounted Displays}, 
year={2016}, 
volume={22}, 
number={7}, 
pages={1912-1931}, 
keywords={augmented reality;gaze tracking;helmet mounted displays;accommodation-free displays;augmented reality;dynamic stereoscopy;eye-tracking-based approach;gaze;guided blur;head-mounted display;monocular HMD;multiscopic HMD;natural focal cues;retinal scanning;stereoscopic HMD;vergence-accommodation conflict;virtual reality;Lenses;Mirrors;Optical imaging;Retina;Stereo image processing;Three-dimensional displays;Head-Mounted Displays;Vergence-Accommodation Conflict;Vergence-accommodation conflict;display;eye tracking;freeform prism;head-mounted;light field;maxwellian view;multifocal plane;multiscopic;pinlight;retinal;scanned fiber}, 
doi={10.1109/TVCG.2015.2473855}, 
ISSN={1077-2626}, 
month={July},}

@inproceedings{Langhans2003Solid,
  title={Solid Felix: a static volume 3D-laser display},
  author={Langhans, Knut and Guill, Christian and Rieper, Elisabeth and Oltmann, Klaas and Bahr, Detlef},
  booktitle={Stereoscopic Displays and Virtual Reality Systems X},
  volume={5006},
  pages={161--175},
  year={2003},
  organization={International Society for Optics and Photonics}
}

@article{Lanman2013near,
 author = {Lanman, Douglas and Luebke, David},
 title = {{Near-eye Light Field Displays}},
 journal = {ACM Trans. Graph.},
 issue_date = {November 2013},
 volume = {32},
 number = {6},
 month = nov,
 year = {2013},
 issn = {0730-0301},
 pages = {220:1--220:10},
 articleno = {220},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2508363.2508366},
 doi = {10.1145/2508363.2508366},
 acmid = {2508366},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {accommodation-convergence conflict, head-mounted displays, light field displays, microlens arrays, virtual reality},
} 

@ARTICLE{Lee2017foveated, 
author={S. Lee and J. Cho and B. Lee and Y. Jo and C. Jang and D. Kim and B. Lee}, 
journal={IEEE Access}, 
title={{Foveated Retinal Optimization for See-Through Near-Eye Multi-Layer Displays}}, 
year={2018}, 
volume={6}, 
number={}, 
pages={2170-2180}, 
keywords={Holography;Image reconstruction;Optical imaging;Optimization;Prototypes;Retina;Three-dimensional displays;Displays;augmented reality;holographic optical elements;optical signal processing}, 
doi={10.1109/ACCESS.2017.2782219}, 
ISSN={}, 
month={},}

@Inbook{Levick1972receptive,
author="Levick, W. R.",
editor="Fuortes, M. G. F.",
title={{Receptive Fields of Retinal Ganglion Cells}},
bookTitle="Physiology of Photoreceptor Organs",
year="1972",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="531--566",
abstract="The concept of receptive field is important because it draws attention to the fact that the sensitivity of a neurone to photic stimuli is spread out over a region. The distribution of sensitivity is a functional sign that neural analysis of the retinal image has begun. The changing visual scene is not like ``snow'' on a television screen: it contains objects which are characterized by properties of local extension and local connectedness of various kinds. In order to detect their presence and progression, neurones must reflect at least some of the properties in their spatial distribution of sensitivity (referred to the receptor mosaic or to the external visual field).",
isbn="978-3-642-65340-7",
doi="10.1007/978-3-642-65340-7_15",
url="https://doi.org/10.1007/978-3-642-65340-7_15"
}


@ARTICLE{Lewis1971True, 
author={J. D. Lewis and C. M. Verber and R. B. McGhee}, 
journal={IEEE Transactions on Electron Devices}, 
title={A true three-dimensional display}, 
year={1971}, 
volume={18}, 
number={9}, 
pages={724-732}, 
keywords={Cathode ray tubes;Computer displays;Electron beams;Fluorescence;Humans;Laboratories;Light sources;Three dimensional displays;Two dimensional displays;Writing}, 
doi={10.1109/T-ED.1971.17273}, 
ISSN={0018-9383}, 
month={Sep},}

@ARTICLE{Lincoln2016motion, 
author={P. Lincoln and A. Blate and M. Singh and T. Whitted and A. State and A. Lastra and H. Fuchs}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={{From Motion to Photons in 80 Microseconds: Towards Minimal Latency for Virtual and Augmented Reality}}, 
year={2016}, 
volume={22}, 
number={4}, 
pages={1367-1376}, 
keywords={augmented reality;computer displays;field programmable gate arrays;rendering (computer graphics);DMD chip;FPGA;augmented reality;binary pixels;binary update rate;display modulation scheme;end-to-end latency;extremely-low-latency display systems;head tracked rig;image quality;just-in-time tracking updates;mechanical tracking;minimal latency;modulation technique;near-zero latency;optical display elements;optical see-through display;perceived gray scale;post-rendering 2-D offsets;reconfigurable display processing;synthetic imagery;virtual reality;Delays;Field programmable gate arrays;Graphics processing units;Modulation;Optical imaging;Rendering (computer graphics);Tracking;Augmented reality;display modulation;latency}, 
doi={10.1109/TVCG.2016.2518038}, 
ISSN={1077-2626}, 
month={April},}

@inproceedings{Lincoln2017scene,
 author = {Lincoln, Peter and Blate, Alex and Singh, Montek and State, Andrei and Whitton, Mary C. and Whitted, Turner and Fuchs, Henry},
 title = {{Scene-adaptive High Dynamic Range Display for Low Latency Augmented Reality}},
 booktitle = {Proceedings of the 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
 series = {I3D '17},
 year = {2017},
 isbn = {978-1-4503-4886-7},
 location = {San Francisco, California},
 pages = {15:1--15:7},
 articleno = {15},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/3023368.3023379},
 doi = {10.1145/3023368.3023379},
 acmid = {3023379},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality, digital micromirror display, high dynamic range, optical see-through},
}

@ARTICLE{Liu2010novel, 
author={S. Liu and H. Hua and D. Cheng}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={{A Novel Prototype for an Optical See-Through Head-Mounted Display with Addressable Focus Cues}}, 
year={2010}, 
volume={16}, 
number={3}, 
pages={381-393}, 
keywords={focal planes;helmet mounted displays;three-dimensional displays;accommodation cue;addressable focus cues;depth perception;display focal distance;eye accommodative response;liquid lens;monocular bench prototype;optical see through head mounted display;real world 3D viewing condition;retinal blur cues;time multiplexed multifocal plane mode;varifocal plane mode;Augmented reality;Convergence;Displays;Focusing;Holographic optical components;Holography;Lenses;Prototypes;Retina;Visualization;Three-dimensional displays;accommodation;convergence;focus cues;mixed and augmented reality;retinal blur;user studies.;Computer Graphics;Cues;Data Display;Equipment Design;Equipment Failure Analysis;Head;Humans;Image Interpretation, Computer-Assisted;Man-Machine Systems;Optical Devices;Pilot Projects;User-Computer Interface}, 
doi={10.1109/TVCG.2009.95}, 
ISSN={1077-2626}, 
month={May},}

@article{Liu2010systematic,
author = {Sheng Liu and Hong Hua},
journal = {Opt. Express},
keywords = {Displays; Heads-up displays; Visual optics, accommodation},
number = {11},
pages = {11562--11573},
publisher = {OSA},
title = {A systematic method for designing depth-fused multi-focal plane three-dimensional displays},
volume = {18},
month = {May},
year = {2010},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-18-11-11562},
doi = {10.1364/OE.18.011562},
abstract = {Lack of accurate focus cues in conventional stereoscopic displays has potentially significant effects on depth perception accuracy and visual fatigue. Recently several multi-focal plane display prototypes have been demonstrated with the promise of improving the accuracy of focus cue rendering in stereoscopic displays. In this paper, we present a systematic method to address two fundamental issues in designing a multi-focal plane display: (1) the appropriate dioptric spacing between adjacent focal planes; and (2) the depth-weighted fusing function to render a continuous three-dimensional (3-D) volume using a sparse number of focal planes placed in the space. By taking account of both ocular factors of the human visual system (HVS) and display factors of a multi-focal plane system, we determine that an appropriate spacing between two adjacent focal planes should be ~0.6 diopter (D) while a smaller spacing may be necessary for further improving retinal image quality. We further develop a set of nonlinear depth-weighted fusing function with the promise of balancing perceptual continuity of a 3-D scene and retinal image quality. Our method was based on quantitative evaluation of the modulation transfer functions (MTF) of depth-fused images formed on retina.},
}

@article{Love2009high,
author = {Gordon D. Love and David M. Hoffman and Philip J.W. Hands and James Gao and Andrew K. Kirby and Martin S. Banks},
journal = {Opt. Express},
keywords = {Displays; Polarization-selective devices; Vision - binocular and stereopsis},
number = {18},
pages = {15716--15725},
publisher = {OSA},
title = {High-speed switchable lens enables the development of a volumetric stereoscopic display},
volume = {17},
month = {Aug},
year = {2009},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-17-18-15716},
doi = {10.1364/OE.17.015716},
abstract = {Stereoscopic displays present different images to the two eyes and thereby create a compelling three-dimensional (3D) sensation. They are being developed for numerous applications including cinema, television, virtual prototyping, and medical imaging. However, stereoscopic displays cause perceptual distortions, performance decrements, and visual fatigue. These problems occur because some of the presented depth cues (i.e., perspective and binocular disparity) specify the intended 3D scene while focus cues (blur and accommodation) specify the fixed distance of the display itself. We have developed a stereoscopic display that circumvents these problems. It consists of a fast switchable lens synchronized to the display such that focus cues are nearly correct. The system has great potential for both basic vision research and display applications.},
}

@INPROCEEDINGS{Maimone2013Computational, 
author={A. Maimone and H. Fuchs}, 
booktitle={2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
title={Computational augmented reality eyeglasses}, 
year={2013}, 
volume={}, 
number={}, 
pages={29-38}, 
keywords={augmented reality;eye;helmet mounted displays;optimisation;three-dimensional displays;compact eyeglasses-like form factor;computational augmented reality eyeglasses;eye accommodation distance;focal depths;focused image;multilayer desktop 3D displays;multilayer display ray constraint;optical see-through head-worn display;optimization formulations;selective occlusion mask;spatial light modulators;Lenses;Modulation;Nonhomogeneous media;Optical diffraction;Optical imaging;Optical refraction;Optimization;augmented reality;three-dimensional displays}, 
doi={10.1109/ISMAR.2013.6671761}, 
ISSN={}, 
month={Oct},}

@inproceedings{Maimone2014Pinlight,
 author = {Maimone, Andrew and Lanman, Douglas and Rathinavel, Kishore and Keller, Kurtis and Luebke, David and Fuchs, Henry},
 title = {{Pinlight Displays: Wide Field of View Augmented Reality Eyeglasses Using Defocused Point Light Sources}},
 booktitle = {ACM SIGGRAPH 2014 Emerging Technologies},
 series = {SIGGRAPH '14},
 year = {2014},
 isbn = {978-1-4503-2961-3},
 location = {Vancouver, Canada},
 pages = {20:1--20:1},
 articleno = {20},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/2614066.2614080},
 doi = {10.1145/2614066.2614080},
 acmid = {2614080},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{MacKenzie2010Accommodation,
author = {MacKenzie, Kevin J. and Hoffman, David M. and Watt, Simon J.},
title = {Accommodation to multiple‐focal‐plane displays: Implications for improving stereoscopic displays and for accommodation control},
journal = {Journal of Vision},
volume = {10},
number = {8},
pages = {22},
year = {2010},
doi = {10.1167/10.8.22},
URL = { + http://dx.doi.org/10.1167/10.8.22},
eprint = {/data/journals/jov/933477/jov-10-8-22.pdf}
}

@article{Maimone2017Holographic,
 author = {Maimone, Andrew and Georgiou, Andreas and Kollin, Joel S.},
 title = {{Holographic Near-eye Displays for Virtual and Augmented Reality}},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2017},
 volume = {36},
 number = {4},
 month = jul,
 year = {2017},
 issn = {0730-0301},
 pages = {85:1--85:16},
 articleno = {85},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/3072959.3073624},
 doi = {10.1145/3072959.3073624},
 acmid = {3073624},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {augmented reality, computational displays, holography, near-eye display, virtual reality},
}

@article{Marran1997Multiaccommodative,
author = {Lynn Marran and Clifton Schor},
title ={{Multiaccommodative Stimuli in VR Systems: Problems \& Solutions}},
journal = {Human Factors},
volume = {39},
number = {3},
pages = {382-388},
year = {1997},
doi = {10.1518/001872097778827070},
note ={PMID: 9394632},
URL = {https://doi.org/10.1518/001872097778827070},
eprint = {https://doi.org/10.1518/001872097778827070} ,
abstract = {Virtual reality environments can introduce multiple and sometimes conflicting accommodative stimuli. For instance, with the high-powered lenses commonly used in head-mounted displays, small discrepancies in screen lens placement, caused by manufacturer error or user adjustment focus error, can change the focal depths of the image by a couple of diopters. This can introduce a binocular accommodative stimulus or, if the displacement between the two screens is unequal, an unequal (anisometropic) accommodative stimulus for the two eyes. Systems that allow simultaneous viewing of virtual and real images can also introduce a conflict in accommodative stimuli: When real and virtual images are at different focal planes, both cannot be in focus at the same time, though they may appear to be in similar locations in space. In this paper four unique designs are described that minimize the range of accommodative stimuli and maximize the visual system's ability to cope efficiently with the focus conflicts that remain: pinhole optics, monocular lens addition combined with aniso-accommodation, chromatic bifocal, and bifocal lens system. The advantages and disadvantages of each design are described and recommendation for design choice is given after consideration of the end use of the virtual reality system (e.g., low or high end, entertainment, technical, or medical use). The appropriate design modifications should allow greater user comfort and better performance.}}

@article{Matsuda2017focal,
 author = {Matsuda, Nathan and Fix, Alexander and Lanman, Douglas},
 title = {{Focal Surface Displays}},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2017},
 volume = {36},
 number = {4},
 month = jul,
 year = {2017},
 issn = {0730-0301},
 pages = {86:1--86:14},
 articleno = {86},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/3072959.3073590},
 doi = {10.1145/3072959.3073590},
 acmid = {3073590},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {caustics, freeform optics, head-mounted displays, multifocal displays, vergence-accommodation conflict},
}

@article{Mercier2017Fast,
 author = {Mercier, Olivier and Sulai, Yusufu and Mackenzie, Kevin and Zannoli, Marina and Hillis, James and Nowrouzezahrai, Derek and Lanman, Douglas},
 title = {{Fast Gaze-contingent Optimal Decompositions for Multifocal Displays}},
 journal = {ACM Trans. Graph.},
 issue_date = {November 2017},
 volume = {36},
 number = {6},
 month = nov,
 year = {2017},
 issn = {0730-0301},
 pages = {237:1--237:15},
 articleno = {237},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/3130800.3130846},
 doi = {10.1145/3130800.3130846},
 acmid = {3130846},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational displays, multifocal displays, multiview rendering, vergence-accommodation conflict},
} 

@article{Narain2015optimal,
 author = {Narain, Rahul and Albert, Rachel A. and Bulbul, Abdullah and Ward, Gregory J. and Banks, Martin S. and O'Brien, James F.},
 title = {{Optimal Presentation of Imagery with Focus Cues on Multi-plane Displays}},
 journal = {ACM Trans. Graph.},
 issue_date = {August 2015},
 volume = {34},
 number = {4},
 month = jul,
 year = {2015},
 issn = {0730-0301},
 pages = {59:1--59:12},
 articleno = {59},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2766909},
 doi = {10.1145/2766909},
 acmid = {2766909},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational displays, eye accommodation, multi-plane displays, retinal blur, vergence-accommodation conflict},
} 

@article{Ochiai2016Fairy,
 author = {Ochiai, Yoichi and Kumagai, Kota and Hoshi, Takayuki and Rekimoto, Jun and Hasegawa, Satoshi and Hayasaki, Yoshio},
 title = {Fairy Lights in Femtoseconds: Aerial and Volumetric Graphics Rendered by Focused Femtosecond Laser Combined with Computational Holographic Fields},
 journal = {ACM Trans. Graph.},
 issue_date = {May 2016},
 volume = {35},
 number = {2},
 month = feb,
 year = {2016},
 issn = {0730-0301},
 pages = {17:1--17:14},
 articleno = {17},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/2850414},
 doi = {10.1145/2850414},
 acmid = {2850414},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Volumetric display, aerial interaction, femtosecond laser, laser plasma, touchable aerial images},
}

@article {Padmanaban2016Optimizing,
	author = {Padmanaban, Nitish and Konrad, Robert and Stramer, Tal and Cooper, Emily A. and Wetzstein, Gordon},
	title = {Optimizing virtual reality for all users through gaze-contingent and adaptive focus displays},
	year = {2017},
	doi = {10.1073/pnas.1617251114},
	publisher = {National Academy of Sciences},
	abstract = {Wearable displays are becoming increasingly important, but the accessibility, visual comfort, and quality of current generation devices are limited. We study optocomputational display modes and show their potential to improve experiences for users across ages and with common refractive errors. With the presented studies and technologies, we lay the foundations of next generation computational near-eye displays that can be used by everyone.From the desktop to the laptop to the mobile device, personal computing platforms evolve over time. Moving forward, wearable computing is widely expected to be integral to consumer electronics and beyond. The primary interface between a wearable computer and a user is often a near-eye display. However, current generation near-eye displays suffer from multiple limitations: they are unable to provide fully natural visual cues and comfortable viewing experiences for all users. At their core, many of the issues with near-eye displays are caused by limitations in conventional optics. Current displays cannot reproduce the changes in focus that accompany natural vision, and they cannot support users with uncorrected refractive errors. With two prototype near-eye displays, we show how these issues can be overcome using display modes that adapt to the user via computational optics. By using focus-tunable lenses, mechanically actuated displays, and mobile gaze-tracking technology, these displays can be tailored to correct common refractive errors and provide natural focus cues by dynamically updating the system based on where a user looks in a virtual scene. Indeed, the opportunities afforded by recent advances in computational optics open up the possibility of creating a computing platform in which some users may experience better quality vision in the virtual world than in the real one.},
	issn = {0027-8424},
	URL = {http://www.pnas.org/content/early/2017/02/07/1617251114},
	eprint = {http://www.pnas.org/content/early/2017/02/07/1617251114.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}


@article{Ravikumar2011creating,
author = {Sowmya Ravikumar and Kurt Akeley and Martin S. Banks},
journal = {Opt. Express},
keywords = {Displays; Vision - binocular and stereopsis},
number = {21},
pages = {20940--20952},
publisher = {OSA},
title = {{Creating effective focus cues in multi-plane 3D displays}},
volume = {19},
month = {Oct},
year = {2011},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-19-21-20940},
doi = {10.1364/OE.19.020940},
abstract = {Focus cues are incorrect in conventional stereoscopic displays. This causes a dissociation of vergence and accommodation, which leads to visual fatigue and perceptual distortions. Multi-plane displays can minimize these problems by creating nearly correct focus cues. But to create the appearance of continuous depth in a multi-plane display, one needs to use depth-weighted blending: i.e., distribute light intensity between adjacent planes. Akeley et al. \[ACM Trans. Graph. 23, 804 (2004)\] and Liu and Hua \[Opt. Express 18, 11562 (2009)\] described rather different rules for depth-weighted blending. We examined the effectiveness of those and other rules using a model of a typical human eye and biologically plausible metrics for image quality. We find that the linear blending rule proposed by Akeley and colleagues \[ACM Trans. Graph. 23, 804 (2004)\] is the best solution for natural stimuli.},
}

@article{Refai2009Static,
author = {Hakki H. Refai},
journal = {J. Display Technol.},
keywords = {},
number = {10},
pages = {391--397},
publisher = {OSA},
title = {{Static Volumetric Three-Dimensional Display}},
volume = {5},
month = {Oct},
year = {2009},
url = {http://jdt.osa.org/abstract.cfm?URI=jdt-5-10-391},
abstract = {We present here the development of a volumetric display based on the two-frequency, two-step upconversion technique using novel techniques for addressing the imaging volume. Two 1024x768 digital micromirror displays, driven by 30-W lasers at 1532 and 850 nm are utilized to generate fast scanning of the image volume in a 17 mmx17 mmx60 mm 2\% erbium-doped lithium yttrium fluoride (YLF) crystal. Experimentally, images at 532 nm were created at 30 (frames)x1024x768 resolution, resulting in almost 23 million voxels, at 500 frames/s, significantly higher than that obtained with three-dimensional (3D) raster scanning (frame is 2D cross-sectional plane of the 3D image). Imaging optics modified from projector systems and fiber-optically coupled to the source, combined with custom designed software for converting two-dimensional (2D) rendering of volumetric images into control signals for the digital micromirror displays allow single-color image generation with no flicker and natural depth cues. Improvements in optical power efficiency and the speed of digital micromirror display controller boards are needed for the system to reach its full potential. The resulting system has the potential to increase resolution to nearly 800 million voxels without viewpoint obstruction and expand to three-color imagery.}}


@inproceedings{Rolland1999dynamic,
  title={Dynamic focusing in head-mounted displays},
  author={Rolland, Jannick P and Krueger, Myron W and Goon, Alexei A},
  booktitle={Stereoscopic Displays and Virtual Reality Systems VI},
  volume={3639},
  pages={463--471},
  year={1999},
doi = {10.1117/12.349412},
URL = {https://doi.org/10.1117/12.349412},
organization={International Society for Optics and Photonics}
}

@inproceedings{Saito2008Laser,
  title={Laser-plasma scanning 3D display for putting digital contents in free space},
  author={Saito, Hideo and Kimura, Hidei and Shimada, Satoru and Naemura, Takeshi and Kayahara, Jun and Jarusirisawad, Songkran and Nozick, Vincent and Ishikawa, Hiroyo and Murakami, Toshiyuki and Aoki, Jun and others},
  booktitle={Stereoscopic Displays and Applications XIX},
  volume={6803},
  pages={680309},
  year={2008},
  organization={International Society for Optics and Photonics}
}

@article{Shen2018Large,
author = {Xin Shen and Bahram Javidi},
journal = {Appl. Opt.},
keywords = {Three-dimensional image acquisition; Displays; Visually coupled optical systems},
number = {7},
pages = {B184--B189},
publisher = {OSA},
title = {Large depth of focus dynamic micro integral imaging for optical see-through augmented reality display using a focus-tunable lens},
volume = {57},
month = {Mar},
year = {2018},
url = {http://ao.osa.org/abstract.cfm?URI=ao-57-7-B184},
doi = {10.1364/AO.57.00B184},
abstract = {We have developed a three-dimensional (3D) dynamic integral-imaging (InIm)-system-based optical see-through augmented reality display with enhanced depth range of a 3D augmented image. A focus-tunable lens is adopted in the 3D display unit to relay the elemental images with various positions to the micro lens array. Based on resolution priority integral imaging, multiple lenslet image planes are generated to enhance the depth range of the 3D image. The depth range is further increased by utilizing both the real and virtual 3D imaging fields. The 3D reconstructed image and the real-world scene are overlaid using an optical see-through display for augmented reality. The proposed system can significantly enhance the depth range of a 3D reconstructed image with high image quality in the micro InIm unit. This approach provides enhanced functionality for augmented information and adjusts the vergence-accommodation conflict of a traditional augmented reality display.},
}

@article{Shi2017Near,
 author = {Shi, Liang and Huang, Fu-Chung and Lopes, Ward and Matusik, Wojciech and Luebke, David},
 title = {Near-eye Light Field Holographic Rendering with Spherical Waves for Wide Field of View Interactive 3D Computer Graphics},
 journal = {ACM Trans. Graph.},
 issue_date = {November 2017},
 volume = {36},
 number = {6},
 month = nov,
 year = {2017},
 issn = {0730-0301},
 pages = {236:1--236:17},
 articleno = {236},
 numpages = {17},
 url = {http://doi.acm.org/10.1145/3130800.3130832},
 doi = {10.1145/3130800.3130832},
 acmid = {3130832},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational photography, computer generated holography, light field, vergence-accommodation conflict},
}

@article{Smalley2018photophoretic,
  title={A photophoretic-trap volumetric display},
  author={Smalley, DE and Nygaard, E and Squire, K and Van Wagoner, J and Rasmussen, J and Gneiting, S and Qaderi, K and Goodsell, J and Rogers, W and Lindsey, M and others},
  journal={Nature},
  volume={553},
  number={7689},
  pages={486},
  year={2018},
  publisher={Nature Publishing Group}
}

@phdthesis{Smalley2013holovideo,
  title={Holovideo on a stick: Integrated optics for holographic video displays},
  author={Smalley, Daniel E},
  year={2013},
  school={Massachusetts Institute of Technology}
}

@inproceedings{Soltan1992Laser,
  title={Laser-based 3-D volumetric display system},
  author={Soltan, Parviz and Trias, John A and Robinson, Waldo R and Dahlke, Weldon J},
  booktitle={High-Resolution Displays and Projection Systems},
  volume={1664},
  pages={177--193},
  year={1992},
doi = {10.1117/12.60362},
URL = {https://doi.org/10.1117/12.60362},  organization={International Society for Optics and Photonics}
}


@proceeding{Sullivan2004Depthcube,
author = {Alan  Sullivan},
title = {{DepthCube solid-state 3D volumetric display}},
journal = {Proc.SPIE},
volume = {5291},
number = {},
pages = {5291 - 5291 - 6},
year = {2004},
doi = {10.1117/12.527543},
URL = {https://doi.org/10.1117/12.527543},
eprint = {}
}

@book{Wandell1995foundations,
  title={Foundations of vision.},
  author={Wandell, Brian A},
  year={1995},
  publisher={Sinauer Associates}
}

@INPROCEEDINGS{Wu2016Content, 
author={W. Wu and P. Llull and I. Tosic and N. Bedard and K. Berkner and N. Balram}, 
booktitle={2016 IEEE International Conference on Multimedia and Expo (ICME)}, 
title={Content-adaptive focus configuration for near-eye multi-focal displays}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-6}, 
keywords={focal planes;optimisation;stereo image processing;three-dimensional displays;content visual quality;content-adaptive focus configuration;dioptric space;focal plane configuration optimization;near-eye light field displays;near-eye multifocal displays;stereoscopic 3D displays;uniformly spaced focal plane configuration;Adaptive optics;Measurement;Optical imaging;Optical sensors;Retina;Three-dimensional displays;Visualization;content adaptation;depth-blending;light field;multi-focal;near-eye display}, 
doi={10.1109/ICME.2016.7552965}, 
ISSN={}, 
month={July},}

@article{Zhan2018High,
author = {Tao Zhan and Yun-Han Lee and Shin-Tson Wu},
journal = {Opt. Express},
keywords = {Phase modulation; Displays; Liquid-crystal devices; Diffractive lenses},
number = {4},
pages = {4863--4872},
publisher = {OSA},
title = {{High-resolution additive light field near-eye display by switchable Pancharatnam--Berry phase lenses}},
volume = {26},
month = {Feb},
year = {2018},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-26-4-4863},
doi = {10.1364/OE.26.004863},
abstract = {Conventional head-mounted displays present different images to each eye, and thereby create three-dimensional (3D) sensation for viewers. This method can only control the stimulus to vergence but not accommodation, which is located at the apparent location of the physical displays. The disrupted coupling between vergence and accommodation could cause considerable visual discomfort. To address this problem, in this paper a novel multi-focal plane 3D display system is proposed. A stack of switchable liquid crystal Pancharatnam-Berry phase lenses is implemented to create real depths for each eye, which is able to provide approximate focus cue and relieve the discomfort from vergence-accommodation conflict. The proposed multi-focal plane generation method has great potential for both virtual reality and augmented reality applications, where correct focus cue is highly desirable.},
}
