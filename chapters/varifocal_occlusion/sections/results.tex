\input{chapters/varifocal_occlusion/figures/fig_results.tex}
\subsection{See-through images}
\label{sec:results_images}
Figures~\ref{fig:varifocal_occlusion:teaser} and \ref{fig:varifocal_occlusion:results} show a comparison of the see-through view of different AR and occlusion technologies. In each of these figures, the augmented scene is composed of real-world objects and virtual placed at different distances. At each distance, one virtual object is placed slightly in front of the real world object to demonstrate our display's ability to occlude real world objects. The mechanism by which the different occlusion and AR displays are emulated is explained in Sec.~\ref{sec:varifocal_occlusion:implementation}. The see-through view for the different AR and occlusion technologies are shown column-wise:
\begin{itemize}
    \item \textbf{Column One:} Emulates commercially available AR displays. In these displays, the virtual imagery looks transparent and is placed at a fixed distance, which does not provides the user with important depth cues like occlusion or accommodation. 
    \item \textbf{Column Two:} Emulates varifocal AR displays. The virtual image plane is movable in these displays and should be designed to match the user's focal distance. A computational blur can be applied optionally to virtual content that is out-of-focus with the focal distance. The improvement over commercially available AR displays is that accommodation cues are provided in a perceptually correct manner, but these displays still lack the ability to show the most important depth cue, namely occlusion~\cite{Cutting:1995}.
    \item \textbf{Column Three:} Emulates fixed-focus occlusion-capable AR displays. In these displays, occlusion of real objects by virtual objects can be displayed, but the occlusion mask and virtual image are always displayed at a fixed depth, which reduces the realism for virtual objects located at other depths. Note how in Fig.~\ref{fig:varifocal_occlusion:results}, all three virtual objects, namely ring, teapot, and bull are in-focus when the camera is focused far and all three objects are defocused when the camera is focused at other distances.
    \item \textbf{Column Four:} Demonstrates our varifocal occlusion-capable AR display. Our display is able to move the occlusion and virtual image planes to different distances, and hence, is able to provide depth-dependent occlusion and accommodation depth cues. Note how in Fig.~\ref{fig:varifocal_occlusion:results}, the camera correctly records only one virtual and one real object in-focus at each focus setting.
    \item \textbf{Columns Five and Six:} Comparison of only the occlusion masks for fixed-focus and varifocal occlusion displays.
\end{itemize}

\subsection{Quality of real world magnification}
\label{sec:results_optimization_quality}
For any AR display, whether occlusion-capable or not, the magnification of see-through images of the real world should be unity irrespective of the virtual image plane distance. Ensuring this property is particularly challenging for a varifocal occlusion-capable AR display. Section \ref{sec:optical_design_optimization} and \ref{sec:optical_design_closed_form} discuss complementary strategies to ensure this. Our prototype display shown in Fig.~\ref{fig:varifocal_occlusion:prototype} was designed using the optimization approach (Sec.~\ref{sec:optical_design_optimization}). For different settings of the occlusion or virtual image plane distance, Tables~\ref{tab:focus_tunable} and ~\ref{tab:optimization_quality} show the focal length settings of the focus-tunable lenses and the magnification of the see-through image respectively. 

Note that the optimization approach (Sec.~\ref{sec:optical_design_optimization}) requires a discretization of only the real-world distances, but accepts continuously changing values for the occlusion mask. Tables~\ref{tab:focus_tunable} and ~\ref{tab:optimization_quality} are calculated for a finite set of occlusion mask distances only to indicate the performance of the display for different occlusion mask distance settings.

Table~\ref{tab:optimization_quality} shows that the optimization predicts that the see-through image magnification values are close to unity, but not exactly equal to unity. Using the closed-form approach would have ensured exact unit magnification for all combinations of real world distance and virtual image plane distance, however, as discussed in Sec.~\ref{sec:varifocal_occlusion:implementation}, due to some hardware constraints, the focal range predicted by the closed-form solutions is unattainable with the focus-tunable lenses at our disposal. Hence, the best we can do currently is the solution predicted by the optimization routine. A similar table could be shown for the other error considered in the optimization approach, i.e. the error in the occlusion or virtual image plane distance (see Eq.~\ref{eq:optimization_error}), however we omit this because these errors are negligible (always less than one centimeter). 

We verify the quality of real-world magnification of our prototype by capturing see-through images of our display for different display focus settings for a fixed camera focus distance (see Fig.~\ref{fig:varifocal_occlusion:constant_magnification}). In the left subfigure, the user is assumed to fixate the  daffodil in the foreground. In this setting, the other flower pot is blurred due to the computational blur that emulates perceived retinal blur. The camera is also focused on the foreground objects. In the right subfigure, the user now fixates at an object at the farther distance and the virtual image distance along with the occlusion mask are updated to the farther distance. We intentionally keep the camera focus on the foreground object to highlight the fact that refocusing the virtual image and the occlusion mask does not change the magnification of the physical scene in a noticeable manner. This is highlighted by the size of the stamp being roughly constant. Note that the user would never see the camera image shown in the right subfigure, because in a varifocal display, the distance of the object they fixate is the same as the virtual image distance. Nevertheless, this experiment demonstrates our prototype display's capability to maintain constant magnification of the real-world independent of the virtual image distance.
\input{chapters/varifocal_occlusion/tables/table_optimization_quality.tex}
\input{chapters/varifocal_occlusion/figures/fig_constant_magnification.tex}

\subsection{Display specifications}
The display's field of view is 15.3$^\circ$. The supported occlusion/virtual image plane depth is from optical infinity to 30~cm. In our results, we do not include real or virtual objects beyond 300~cm because 300~cm seems equivalent to optical infinity for the display. The eyebox is about 1~cm, equal to the aperture of the last lens in the system. 
